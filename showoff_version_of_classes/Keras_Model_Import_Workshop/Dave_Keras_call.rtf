{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red98\green175\blue30;\red100\green100\blue100;\red191\green191\blue191;
\red26\green26\blue26;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720

\itap1\trowd \taflags4 \trgaph108\trleft-108 \trcbpat1 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth2140\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf4 \clbrdrl\brdrs\brdrw20\brdrcf4 \clbrdrb\brdrs\brdrw20\brdrcf4 \clbrdrr\brdrs\brdrw20\brdrcf4 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720

\f0\b\fs26 \cf2 \expnd0\expndtw0\kerning0
igh me\cell 
\pard\intbl\itap1\pardeftab720\qr

\b0\fs22 \cf3 \expnd0\expndtw0\kerning0
2:25 PM\cell \lastrow\row
\pard\pardeftab720

\fs26 \cf5 \expnd0\expndtw0\kerning0
Keras is a high level python based dl framwork\
for training and configuring NN based models\
Wanna build NN use Keras\
More popular\
So that is high level,\
one level down Keras vs Caffe vs Tensorflowr vs MXNet\
--\
Keras is an abstraction layer that sits on top of tf and theano\
--\
TF and theano both are symbolic math libraries\
--\
arbitrary Math function on some input\
--\
Theano and tensorflow share same inspiration\
--\
mathematical expression compiler and evaluator\
provides "symbolic differentiation" so we can apply derivatives\
--\
allows you to make a big expression and apply exp.grad\
--\
so it gives us cheap and easy backprop\
--\
so by hand in octav or mattlab\
--\
once again "symbolic differentiation"\
--\
good for rapid protyping\
--\
Incredibly flexible and useful\
--\
So Keras makes the easy part even easier\
--\
abstraction on top of those TF and Theano\
--\
All deep Learning is at the end of the day, C and Cuda\
__\
* note to tom, learn mxnet definition\
--\
We built nd4j with NN in mind\
Not so much with Numpy\
our unified backend is better than most, but mxnet is coming up\
--\
read fchollet blog for K2\
--\
three stages\
1 describe model\
--\
until you call compile all you have done is describe\
2. is build model\
3.\
is train the model\
4 is inference\
###that 4 step thing is great use tha\
@@\
!!!\
hello\
--\
Why dl4j, because JAVA\
or Hadoop drives it\
or Spark\
--\
Keras has largest dev community\
--\
Composition of functions that are end to end differentiable so they can be trained end to end.\
}